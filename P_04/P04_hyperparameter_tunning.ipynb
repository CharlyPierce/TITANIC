{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustaremos los parametros en Vertex AI haciendo uso de hyperparameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.2\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El propósito es la implementación de hyperparameter_tuning en la nube\n",
    "Para definir el modelo por subclassing, el cual recibirá los hiperparámetros\n",
    "para encontrar los mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el modelo dentro de una función que recibirá todos los hiperparámetros para la búsqueda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyper/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyper/model.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def hyperparameter_tun(d1,d2,lr,epochs,batch):\n",
    "    \"\"\"\n",
    "    Esta función crea y entrena un modelo utilizando los hiperparámetros proporcionados.\n",
    "\n",
    "    :param d1: Número de neuronas en la primera capa densa.\n",
    "    :type d1: int\n",
    "    :param d2: Número de neuronas en la segunda capa densa.\n",
    "    :type d2: int\n",
    "    :param lr: Tasa de aprendizaje para el optimizador Adam.\n",
    "    :type lr: float\n",
    "    :param epochs: Número de épocas para entrenar el modelo.\n",
    "    :type epochs: int\n",
    "    :param batch: Tamaño del lote para el entrenamiento.\n",
    "    :type batch: int\n",
    "    :return: La precisión de validación del modelo entrenado en la última época.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    # Subclassing\n",
    "    class MyModel(tf.keras.Model):  # Hereda de tf.keras.Model.\n",
    "        def __init__(self, d2):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.dense = tf.keras.layers.Dense(d2)\n",
    "\n",
    "        def call(self, x):\n",
    "            return self.dense(x)\n",
    "\n",
    "    class MyModel2(MyModel):  # Hereda de MyModel.\n",
    "        def __init__(self, d1=10,d2=10):\n",
    "            super(MyModel2, self).__init__(d2)\n",
    "            self.dense2 = tf.keras.layers.Dense(d1)\n",
    "            self.dense3 = tf.keras.layers.Dense(1)\n",
    "\n",
    "        def call(self, x):\n",
    "            x = super().call(x)  # Llama al método call de MyModel.\n",
    "            x = self.dense2(x)\n",
    "            return self.dense3(x)\n",
    "        \n",
    "    model = MyModel2(d1,d2)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='MSE', metrics=['accuracy'])\n",
    "    \n",
    "    x_train = np.random.random((1000, 10))\n",
    "    y_train = np.random.randint(2, size=(1000,))\n",
    "    x_val = np.random.random((200, 10))\n",
    "    y_val = np.random.randint(2, size=(200,))\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data=(x_val, y_val))\n",
    "\n",
    "    hp_metric = history.history['val_accuracy'][-1]\n",
    "    # Evaluar el modelo\n",
    "    x_test = np.random.random((200, 10))\n",
    "    y_test = np.random.randint(2, size=(200,))\n",
    "    evv = model.evaluate(x_test, y_test)\n",
    "    print(\"HERE: \",evv)\n",
    "    model.save('model/m1')\n",
    "    return hp_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este script es el módulo principal que se ejecuta al iniciar la imagen Docker, facilitando la búsqueda automatizada de los hiperparámetros óptimos para un modelo de machine learning en la plataforma AI de Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyper/hyper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyper/hyper.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from model import hyperparameter_tun\n",
    "import argparse\n",
    "import hypertune\n",
    "\n",
    "def get_args():\n",
    "  '''Parses args. Must include all hyperparameters you want to tune.'''\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--dense1',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='dense1')\n",
    "  parser.add_argument(\n",
    "      '--dense2',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='dense2')\n",
    "  parser.add_argument(\n",
    "      '--lr',\n",
    "      required=True,\n",
    "      type=float,\n",
    "      help='learning rate')\n",
    "  parser.add_argument(\n",
    "      '--epochs',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='epochs')\n",
    "  parser.add_argument(\n",
    "      '--batch',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='batch')\n",
    "  args = parser.parse_args()\n",
    "  return args\n",
    "\n",
    "def main():\n",
    "  args = get_args()\n",
    "  hp_metric = hyperparameter_tun(d1=args.dense1,d2=args.dense2,lr=args.lr,epochs=args.epochs,batch=args.batch)\n",
    "    \n",
    "  hpt = hypertune.HyperTune()\n",
    "\n",
    "  hpt.report_hyperparameter_tuning_metric(\n",
    "      hyperparameter_metric_tag='accuracy',\n",
    "      metric_value=hp_metric,\n",
    "      global_step=args.epochs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyper/.dockerignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyper/.dockerignore\n",
    "\n",
    "__pycache__\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.egg-info\n",
    "**/model/m0/\n",
    "**/model/m1/\n",
    "Dockerfile\n",
    "\n",
    "env/\n",
    ".git\n",
    ".dockerignore\n",
    ".gitignore\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.egg-info\n",
    "*.egg\n",
    "\n",
    "# Entornos virtuales\n",
    "venv/\n",
    ".env/\n",
    "env\n",
    "**/__pycache__\n",
    "__pycache__\n",
    "*.virtualenv/\n",
    "\n",
    "# Generales\n",
    ".DS_Store\n",
    "*.log\n",
    ".idea/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un Dockerfile para la imagen de búsqueda de hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyper/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyper/Dockerfile\n",
    "\n",
    "#FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-8\n",
    "FROM gcr.io/deeplearning-platform-release/tf-gpu.2-6.py39\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Actualiza pip\n",
    "RUN pip install --upgrade pip\n",
    "# Copia el archivo requirements.txt al contenedor\n",
    "COPY requirements.txt /requirements.txt\n",
    "# Instala las dependencias\n",
    "RUN pip install -r /requirements.txt\n",
    "# Installs hypertune library\n",
    "RUN pip install cloudml-hypertune\n",
    "\n",
    "# Copies the trainer code to the Docker image.\n",
    "COPY . .\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"hyper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source env/bin/activate && pip freeze > hyper/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t hyper hyper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag hyper us-central1-docker.pkg.dev/projecto2-373519/myimages/hyper:v1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push us-central1-docker.pkg.dev/projecto2-373519/myimages/hyper:v1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración del Tipo de Máquina y Aceleradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": None, #\"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": None,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": \"us-central1-docker.pkg.dev/projecto2-373519/myimages/hyper:v1.0.0\"\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_custom_job = aiplatform.CustomJob(\n",
    "    display_name=\"tunning\",\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=\"gs://models_ai_save_2/tunning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {\"accuracy\": \"maximize\"}\n",
    "parameter_spec = {\n",
    "    \"dense1\": hpt.DiscreteParameterSpec(values=[5, 6], scale=None),\n",
    "    \"dense2\": hpt.DiscreteParameterSpec(values=[4, 5, 6], scale=None),\n",
    "    \"lr\": hpt.DoubleParameterSpec(min=0.001, max=1, scale=\"log\"),\n",
    "    \"epochs\": hpt.DiscreteParameterSpec(values=[2, 3, 4], scale=None),\n",
    "    \"batch\": hpt.DiscreteParameterSpec(values=[8, 16, 32], scale=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=\"tunning_params\",\n",
    "    custom_job=my_custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=3,\n",
    "    parallel_trial_count=3,\n",
    ")\n",
    "\n",
    "hp_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
